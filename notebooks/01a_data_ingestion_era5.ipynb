{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Imports",
   "id": "77c83102e976dfe3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:39:44.842836Z",
     "start_time": "2025-08-21T13:39:42.731263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Core scientific and data libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "from shapely.lib import unary_union\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from dask.distributed import Client\n",
    "import time\n",
    "\n"
   ],
   "id": "799505498c75b301",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Variables\n",
   "id": "ffa768fe592de812"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:39:44.954236Z",
     "start_time": "2025-08-21T13:39:44.949943Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_url = 'gs://gcp-public-data-arco-era5/co/single-level-reanalysis.zarr'",
   "id": "97df7811dd489449",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Helper Functions",
   "id": "3681e242326c231c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:39:45.793595Z",
     "start_time": "2025-08-21T13:39:45.787414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lon_to_360(x):\n",
    "    return (360 + (x % 360)) % 360\n",
    "\n",
    "def get_region_shape(region, shapefile = '../data/raw/shapefiles_regions/NSIDC-0780_SeaIceRegions_NH_v1.0.shp'):\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "\n",
    "    region_of_interest = gdf[gdf['Region'] == region]\n",
    "\n",
    "    geom = unary_union(region_of_interest.geometry)\n",
    "\n",
    "    return geom.iloc[0]\n",
    "\n",
    "def get_pan_arctic_shape():\n",
    "    gdf = gpd.read_file('../data/raw/shapefiles_regions/NSIDC-0780_SeaIceRegions_NH_v1.0.shp').to_crs(\"EPSG:4326\")\n",
    "\n",
    "    name_col = \"Region\"\n",
    "    excl = {\"Baltic\",\"Japan\",\"Bohai\",\"Gulf_Alaska\",\"St_Lawr\",\"Okhotsk\"}\n",
    "    incl = [n for n in gdf[name_col] if n not in excl]\n",
    "\n",
    "    pan_arctic_geom = unary_union(gdf[gdf[name_col].isin(incl)].geometry)\n",
    "    return pan_arctic_geom.iloc[0]\n",
    "\n",
    "def slice_dataset_to_region(dataset, region):\n",
    "    if region == \"pan_arctic\":\n",
    "        geom = get_pan_arctic_shape()\n",
    "    else:\n",
    "        geom = get_region_shape(region)\n",
    "    lon = dataset[\"longitude\"].compute().values\n",
    "    lat = dataset[\"latitude\"].compute().values\n",
    "    pts = shapely.points(lon, lat)\n",
    "    mask_vals = shapely.contains(geom, pts)\n",
    "    mask = xr.DataArray(mask_vals, dims=(\"values\",))\n",
    "    return dataset.where(mask, drop=True)\n"
   ],
   "id": "62dba1bd394e3ea0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:40:07.466683Z",
     "start_time": "2025-08-21T13:39:46.546165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Opening the dataset\n",
    "reanalysis = xr.open_zarr(\n",
    "    dataset_url,\n",
    "    chunks={'time': 48, 'values': 250_000},\n",
    "    consolidated=True,)\n",
    "\n",
    "reanalysis = reanalysis.assign_coords(longitude=((reanalysis.longitude + 180) % 360) - 180)"
   ],
   "id": "3f197961012e1b7f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stein\\AppData\\Local\\Temp\\ipykernel_14000\\4168846803.py:2: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  reanalysis = xr.open_zarr(\n",
      "C:\\Users\\stein\\AppData\\Local\\Temp\\ipykernel_14000\\4168846803.py:2: UserWarning: The specified chunks separate the stored chunks along dimension \"values\" starting at index 250000. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  reanalysis = xr.open_zarr(\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:40:07.492718Z",
     "start_time": "2025-08-21T13:40:07.484797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_and_cache_mask():\n",
    "    coords_only = xr.open_zarr(dataset_url, chunks={'values': -1})\n",
    "    lon = coords_only[\"longitude\"].compute().values\n",
    "    lat = coords_only[\"latitude\"].compute().values\n",
    "\n",
    "    geom = get_pan_arctic_shape()\n",
    "    pts = shapely.points(lon, lat)\n",
    "    mask_vals = shapely.contains(geom, pts)\n",
    "\n",
    "    np.save('../data/processed/pan_arctic_mask.npy', mask_vals)\n",
    "    return mask_vals\n",
    "\n",
    "def load_and_apply_mask(dataset):\n",
    "    mask_vals = np.load('../data/processed/pan_arctic_mask.npy')\n",
    "    mask = xr.DataArray(mask_vals, dims=(\"values\",))\n",
    "    return dataset.where(mask, drop=True)"
   ],
   "id": "7c481ec2b7542b88",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:40:14.952201Z",
     "start_time": "2025-08-21T13:40:07.506027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "create_and_cache_mask()\n",
    "ds_roi = load_and_apply_mask(reanalysis)"
   ],
   "id": "d29e65450d6ea415",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stein\\AppData\\Local\\Temp\\ipykernel_14000\\624054296.py:2: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  coords_only = xr.open_zarr(dataset_url, chunks={'values': -1})\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:40:17.136559Z",
     "start_time": "2025-08-21T13:40:14.963544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "ds_roi = ds_roi.chunk({'time': 1440, 'values': -1})\n",
    "\n",
    "lat = ds_roi[\"latitude\"]\n",
    "w = xr.DataArray(np.cos(np.deg2rad(lat)), dims=(\"values\",))\n"
   ],
   "id": "a04a590aafba4529",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-21T13:40:53.147492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_for_duplicates(year, base_dir=\"../data/processed\"):\n",
    "    outpath = Path(base_dir) / f\"pan_arctic_{year}.parquet\"\n",
    "    if outpath.exists():\n",
    "        print(f\"[skip ] {year} → {outpath} (already exists)\")\n",
    "        return True, str(outpath)\n",
    "    return False, str(outpath)\n",
    "\n",
    "\n",
    "client = Client(n_workers=4, threads_per_worker=3, memory_limit=\"10GB\")\n",
    "\n",
    "years = range(1979, 2022)\n",
    "for y in years:\n",
    "    exists, outpath = check_for_duplicates(y)\n",
    "    if exists:\n",
    "        continue\n",
    "\n",
    "    print(f\"[start] {y}\")\n",
    "    t0 = time.perf_counter()\n",
    "    block = (ds_roi[[\"t2m\", \"u10\", \"v10\"]]\n",
    "             .sel(time=slice(f\"{y}-01-01\", f\"{y}-12-31\"))\n",
    "             .resample(time=\"1D\").mean()\n",
    "             .weighted(w).mean(\"values\"))\n",
    "\n",
    "    df_y = (block.assign(t2m_c=lambda d: d.t2m - 273.15)\n",
    "            .drop_vars(\"t2m\")\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns={\"time\": \"date\"}))\n",
    "    df_y[\"region\"] = \"pan_arctic\"\n",
    "    df_y = df_y[[\"date\", \"region\", \"t2m_c\", \"u10\", \"v10\"]]\n",
    "    Path(outpath).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    table = pa.Table.from_pandas(df_y, preserve_index=False)\n",
    "    pq.write_table(table, outpath)\n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"[done ] {y} → {outpath} ({dt:.1f}s)\")\n"
   ],
   "id": "eb6cb8e9be5f50d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip ] 1979 → ..\\data\\processed\\pan_arctic_1979.parquet (already exists)\n",
      "[skip ] 1980 → ..\\data\\processed\\pan_arctic_1980.parquet (already exists)\n",
      "[skip ] 1981 → ..\\data\\processed\\pan_arctic_1981.parquet (already exists)\n",
      "[skip ] 1982 → ..\\data\\processed\\pan_arctic_1982.parquet (already exists)\n",
      "[skip ] 1983 → ..\\data\\processed\\pan_arctic_1983.parquet (already exists)\n",
      "[skip ] 1984 → ..\\data\\processed\\pan_arctic_1984.parquet (already exists)\n",
      "[skip ] 1985 → ..\\data\\processed\\pan_arctic_1985.parquet (already exists)\n",
      "[skip ] 1986 → ..\\data\\processed\\pan_arctic_1986.parquet (already exists)\n",
      "[skip ] 1987 → ..\\data\\processed\\pan_arctic_1987.parquet (already exists)\n",
      "[skip ] 1988 → ..\\data\\processed\\pan_arctic_1988.parquet (already exists)\n",
      "[skip ] 1989 → ..\\data\\processed\\pan_arctic_1989.parquet (already exists)\n",
      "[skip ] 1990 → ..\\data\\processed\\pan_arctic_1990.parquet (already exists)\n",
      "[skip ] 1991 → ..\\data\\processed\\pan_arctic_1991.parquet (already exists)\n",
      "[skip ] 1992 → ..\\data\\processed\\pan_arctic_1992.parquet (already exists)\n",
      "[skip ] 1993 → ..\\data\\processed\\pan_arctic_1993.parquet (already exists)\n",
      "[skip ] 1994 → ..\\data\\processed\\pan_arctic_1994.parquet (already exists)\n",
      "[skip ] 1995 → ..\\data\\processed\\pan_arctic_1995.parquet (already exists)\n",
      "[skip ] 1996 → ..\\data\\processed\\pan_arctic_1996.parquet (already exists)\n",
      "[skip ] 1997 → ..\\data\\processed\\pan_arctic_1997.parquet (already exists)\n",
      "[skip ] 1998 → ..\\data\\processed\\pan_arctic_1998.parquet (already exists)\n",
      "[skip ] 1999 → ..\\data\\processed\\pan_arctic_1999.parquet (already exists)\n",
      "[skip ] 2000 → ..\\data\\processed\\pan_arctic_2000.parquet (already exists)\n",
      "[skip ] 2001 → ..\\data\\processed\\pan_arctic_2001.parquet (already exists)\n",
      "[skip ] 2002 → ..\\data\\processed\\pan_arctic_2002.parquet (already exists)\n",
      "[skip ] 2003 → ..\\data\\processed\\pan_arctic_2003.parquet (already exists)\n",
      "[skip ] 2004 → ..\\data\\processed\\pan_arctic_2004.parquet (already exists)\n",
      "[skip ] 2005 → ..\\data\\processed\\pan_arctic_2005.parquet (already exists)\n",
      "[skip ] 2006 → ..\\data\\processed\\pan_arctic_2006.parquet (already exists)\n",
      "[skip ] 2007 → ..\\data\\processed\\pan_arctic_2007.parquet (already exists)\n",
      "[start] 2008\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "client.close()\n",
   "id": "831bf67c7c06e4b1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
